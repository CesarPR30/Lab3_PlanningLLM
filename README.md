# üß† Laboratorio 3 ‚Äì Planning con Qwen3-8B

Este repositorio contiene la soluci√≥n para el **Laboratorio 3: Planning**, donde se debe dise√±ar un agente capaz de resolver problemas l√≥gicos de m√∫ltiples pasos dentro de una simulaci√≥n virtual usando **Qwen3-8B** con inferencia determinista.

El agente recibe escenarios descritos en lenguaje natural y genera una **secuencia de acciones** para alcanzar el objetivo.

---
## Colab

Link: 
https://colab.research.google.com/drive/1MCz9s9pYaYHUccPanRlkV3Wd3WWHIMHF?usp=sharing




---

## üéØ Objetivo

Dise√±ar un agente que:

- Use exclusivamente **Qwen3-8B**
- Use inferencia determinista (**temperature=0.0**, `do_sample=False`)
- Respete el l√≠mite de **2 minutos por task en Colab**
- Procese `Task.json` y genere un `submission.json`
- Calcule y devuelva:
  - `complexity_level`
  - `target_action_sequence`

---

## üìÅ Estructura del repositorio

```
submit.py        -> Genera submission.json
evaluator.py     -> M√©trica usada en la evaluaci√≥n
student_agent.py -> Implementaci√≥n del agente (archivo principal evaluado)
llm_engine.py    -> Carga de Qwen3-8B y wrapper de inferencia
dev_test.py      -> Script para probar el agente y ver score
Examples.json    -> Dataset de desarrollo con soluciones √≥ptimas
Task.json        -> Dataset de evaluaci√≥n (solo escenarios)
colab.ipynb      -> Notebook con todo integrado para correr en Colab
README.md        -> Este archivo
```

‚ö†Ô∏è Importante:

El archivo que se revisa en la auditor√≠a es:

```
student_agent.py
```

---

## üß† Arquitectura del agente

La soluci√≥n usa:

- Prompt Engineering con reglas estrictas
- Few-shot prompting usando Examples.json
- Retrieval por similitud (Jaccard)
- Separaci√≥n por dominio:
  - Objects domain
  - Blocks domain
- Inferencia determinista con Qwen3-8B
- Generaci√≥n de planes m√≠nimos

El agente:

1. Detecta el dominio (blocks / objects)
2. Extrae el √∫ltimo STATEMENT
3. Busca ejemplos similares
4. Construye prompt con reglas
5. Llama a Qwen3-8B
6. Devuelve lista de acciones

---

## ‚úÖ Configuraci√≥n obligatoria del modelo

El laboratorio exige:

```
temperature = 0.0
do_sample = False
top_p = 1.0
```

Ejemplo:

```python
resp = qwen(
    prompt=prompt,
    system=system,
    temperature=0.0,
    do_sample=False,
    top_p=1.0,
    max_new_tokens=256,
    enable_thinking=False,
    stream=False
)
```

Esto asegura:

- reproducibilidad
- auditor√≠a correcta
- leaderboard v√°lido

---

## üöÄ C√≥mo ejecutar

### 1) Test en desarrollo

```
python dev_test.py
```

Esto:

- carga Examples.json
- ejecuta el agente
- calcula score
- muestra tiempo por task

---

### 2) Generar submission

```
python submit.py
```

Esto:

- lee Task.json
- ejecuta todos los tasks
- crea submission.json

Formato esperado:

```
[
  {
    "assembly_task_id": "...",
    "complexity_level": 4,
    "target_action_sequence": [
      "(attack a)",
      "(overcome a b)"
    ]
  }
]
```

---

### 3) Ejecutar en Colab

Abrir:

```
colab.ipynb
```

Este notebook contiene:

- instalaci√≥n
- carga del modelo
- ejecuci√≥n de tests
- generaci√≥n de submission.json

---

## ‚è± Restricci√≥n de tiempo

M√°ximo permitido:

```
2 minutos por task
```

Para cumplirlo:

- pocos shots
- prompts compactos
- max_new_tokens limitado
- temperature = 0

---

## üîç Auditor√≠a

El profesor verificar√°:

- que se use Qwen3-8B
- que temperature = 0
- que las salidas sean deterministas
- que student_agent.py produzca lo mismo

Por eso el c√≥digo usa:

```
do_sample=False
temperature=0.0
top_p=1.0
```

---

## üìä Estrategias usadas

- Few-shot retrieval
- Prompt rules estrictas
- Domain-specific prompting
- Deterministic decoding
- Minimal plan bias
- Goal-focused constraints

Esto mejora el score sin romper las reglas.

---

## üíª Colab

Link:  
https://colab.research.google.com/drive/1MCz9s9pYaYHUccPanRlkV3Wd3WWHIMHF?usp=sharing

---


## üë§ Grupo - OptimusPrime

- C√©sar Eduardo Pajuelo Reyes
- Gonzalo Alonso Rodriguez Gutierrez
